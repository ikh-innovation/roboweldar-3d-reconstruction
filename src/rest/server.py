import ctypes
import logging
import os
import signal
import threading
import time
from typing import List
import simplejson as json
import pyfiware
from threading import Event
from flask import Flask

from config import ROOT_DIR
from src.log_parsing.log_parser import ReconstructionStep
from src.log_parsing.scheduler import batch_parse_logs
from src.logging_config import ColorFormatter
from src.reconstruction.reconstruction import ThreeDReconstruction
from src.runner import SharedData, reconstruction, post_updates, log_parsing

# logging

logger = logging.getLogger("3d-reconstruction-service")
logger.setLevel(logging.DEBUG)
# create file handler which logs even debug messages
fh = logging.FileHandler('web_service.log')
fh.setLevel(logging.DEBUG)
# log errors to stdout
ch = logging.StreamHandler()
ch.setLevel(logging.ERROR)
# create formatter and add it to the handlers
formatter = ColorFormatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
ch.setFormatter(formatter)
fh.setFormatter(formatter)
# add the handlers to logger
logger.addHandler(ch)
logger.addHandler(fh)

# Flask
app = Flask(__name__)


class StoppingThread(threading.Thread):

    def __init__(self, name, shared_data):
        """ constructor, setting initial variables """
        self._stop_event = threading.Event()
        self._sleep_period = 1.0
        self.shared_data = shared_data

        threading.Thread.__init__(self, name=name)

    def run(self):
        """ Example main control loop """
        count = 0
        while not self._stop_event.isSet():
            count += 1
            self._stop_event.wait(self._sleep_period)

    def join(self, timeout=None):
        """ Stop the thread. """
        self._stop_event.set()
        print("set stop event")
        threading.Thread.join(self, timeout)


class ReconstructionThread(StoppingThread):
    def run(self):
        logger.debug("Starting Meshroom reconstruction thread...")

        # TODO: Provide links to images as arguments and download
        #  them to the "raw" dir prior to running further code

        threedreconstruction = ThreeDReconstruction(
            path_to_meshroom_root=os.path.join(ROOT_DIR, "deps", "Meshroom-2019.2.0"),
            path_to_images_dir=os.path.join(ROOT_DIR, "test", "box_reconstruction", "raw"),
            path_to_output_dir=os.path.join(ROOT_DIR, "test", "box_reconstruction", "output"),
            path_to_cache_dir=os.path.join(ROOT_DIR, "test", "box_reconstruction", "cache")
        )

        # If process returns exit code 0, it has completed successfully
        logger.info("Before start!!!!!")

        process = threedreconstruction.start()
        logger.info("After start!!!!!")

        # Get stuck in this loop until stopevent flag is set, otherwise reach end of execution and terminate thread
        while not self._stop_event.isSet():
            self._stop_event.wait(self._sleep_period)

        #######################################
        # Code for parsing STDOUT of process and logging it
        #
        # output = ""
        # for line in iter(process.stdout.readline, ""):
        #     logger.info(line)
        #     output += str(line)
        #
        # process.wait()
        # exit_code = process.returncode
        #
        # if exit_code == 0:
        #     return output
        # else:
        #     raise Exception(command, exit_code, output)
        #

        ######################################

        # If execution gets here before 3dreconstruction is finished, it kills the process

        # TODO: This works but should not kill process like that as it might kill other sessions on the server,
        #  unless dockerization is used for every client connection instance

        threedreconstruction.kill()

        logger.info("Exiting Meshroom reconstruction thread...")


class LogParserThread(StoppingThread):
    def run(self):
        # this thread will do the log parsing, and conversion into an appropriate data model
        logger.info("Starting Meshroom log parsing...")

        # while the stopflag is not set, keep parsing the logs generated by Meshroom
        while not self._stop_event.isSet():
            try:
                shared_data.logs = batch_parse_logs(
                    path_to_cache_dir=os.path.join(ROOT_DIR, "test", "box_reconstruction", "cache"))
            except FileNotFoundError as err:
                logger.error(msg=err)
                continue
            except Exception as err:
                logger.error(msg=err)
                break

            self._stop_event.wait(self._sleep_period)

        logger.info("Exiting Meshroom log parsing...")


class UpdatesThread(StoppingThread):
    def run(self):

        logger.info("Starting update thread...")

        # while the stopflag is not set, keep posting updates to the Context Broker
        while not self._stop_event.isSet():
            try:
                if shared_data.logs:
                    for step in shared_data.logs:
                        logger.info("Sending mock POST request with data: {}".format(step))
                        # TODO: Need to create a REST service that sends updates to the Context Broker
            # except FileNotFoundError as err:
            #     logger.error(msg=err)
            #     continue
            except Exception as err:
                logger.error(msg=err)
                break

            self._stop_event.wait(self._sleep_period)

        logger.info("Stopping update thread...")


# Shared data between threads
shared_data = SharedData(None)
# Share threads among routes
threads = []

reconstruction_thread = ReconstructionThread(name="reconstruction_thread", shared_data=shared_data)
# rest and log-parsing threads run infinitely and does not exit on its own, so it should be run in a daemonic thread
post_updates_thread = UpdatesThread(name="post_updates_thread", shared_data=shared_data)
logparser_thread = LogParserThread(name="log_parsing_thread", shared_data=shared_data)


@app.route("/start")
def start():
    # TODO:  JSON payload should contain downloadable links to images
    reconstruction_thread = ReconstructionThread(name="reconstruction_thread", shared_data=shared_data)
    # rest and log-parsing threads run infinitely and does not exit on its own, so it should be run in a daemonic thread
    post_updates_thread = UpdatesThread(name="post_updates_thread", shared_data=shared_data)
    logparser_thread = LogParserThread(name="log_parsing_thread", shared_data=shared_data)
    reconstruction_thread.start()
    threads.append(reconstruction_thread)
    logparser_thread.start()
    threads.append(logparser_thread)
    post_updates_thread.start()
    threads.append(post_updates_thread)

    return "Started 3D reconstruction..."


@app.route("/stop")
def stop():
    if len(threads) == 3:
        threads[2].join()
        threads[1].join()
        threads[0].join()
        return "Stopped 3D reconstruction..."
    else:
        return "No running instance of 3D reconstruction..."


def convert_to_ngsi_format(reconstruction_steps: List[ReconstructionStep]):
    startedAt = min([step.datetime_start for step in reconstruction_steps if step.datetime_start])

    if all([step.status == "SUCCESS" for step in reconstruction_steps]):
        endedAt = max([step.datetime_end for step in reconstruction_steps])
    else:
        endedAt = None

    percentageOverallProgress = sum([step.status == "SUCCESS" for step in reconstruction_steps]) / len(
        reconstruction_steps)

    d = {
        "id": "StructureFromMotionService-{}".format(str(startedAt)),
        "type": "Computation",
        "address": {
            "addressLocality": "Athens",
            "addressCountry": "GR"
        },
        "inputFiles": [
            {
                "id": "IMG_0001.JPG",
                "url": "http://pjf0349ts.net/uploads/IMG_0001.JPG"
            },
            {
                "id": "IMG_0002.JPG",
                "url": "http://pjf0349ts.net/uploads/IMG_0002.JPG"
            },
            {
                "id": "IMG_0003.JPG",
                "url": "http://pjf0349ts.net/uploads/IMG_0003.JPG"
            }
        ],
        "outputFiles": [
            {
                "id": "test.OBJ",
                "url": "http://pjf0349ts.net/outputs/test.OBJ"
            },
            {
                "id": "test.STL",
                "url": "http://pjf0349ts.net/outputs/test.STL"
            }
        ],
        "dataProvider": "iKnowHow SA",
        "startedAt": startedAt,
        "endedAt": endedAt,
        "percentageOverallProgress": percentageOverallProgress,
        "children": [],
        "location": {
            "type": "Point",
            "coordinates": [
                -4.754444444,
                41.64833333
            ]
        }
    }

    for step in reconstruction_steps:
        d["children"].append({step.__class__.__name__:

                                  {s: getattr(step, s, None) for s in dir(step) if
                                   isinstance(getattr(type(step), s, None), property)}

                              })

    return json.dumps(d, indent=4, sort_keys=True, default=str)


@app.route("/status")
def status():
    status = convert_to_ngsi_format(shared_data.logs)

    return status


if __name__ == '__main__':
    app.run()
